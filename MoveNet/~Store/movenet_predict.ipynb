{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import tqdm\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load MoveNet Thunder model\n",
    "from script.data import BodyPart\n",
    "from script.ml import Movenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Define function to run pose estimation using MoveNet Thunder.  You'll apply MoveNet's cropping algorithm and run inference\n",
    "# multiple times on the input image to improve pose estimation accuracy.\n",
    "def detect(input_tensor, inference_count=3, per=None):\n",
    "  # Detect pose using the full input image\n",
    "  move_net = Movenet('./model/movenet_thunder')\n",
    "  move_net.detect(input_tensor.numpy(), reset_crop_region=True)\n",
    "  # Repeatedly using previous detection result to identify the region of interest and only cropping that region to improve\n",
    "  # detection accuracy\n",
    "  for _ in range(inference_count - 1):\n",
    "    per = move_net.detect(input_tensor.numpy(), reset_crop_region=False)\n",
    "\n",
    "  return per"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "class MoveNetMark(object):\n",
    "  \"\"\"Helper class to preprocess pose sample images for classification.\"\"\"\n",
    "  def __init__(self, images_in_folder, csvs_out_path):\n",
    "    self._images_in_folder = images_in_folder\n",
    "    self._csvs_out_path = csvs_out_path\n",
    "\n",
    "  def process(self, detection_threshold=0.1):\n",
    "    # Loop through the classes and preprocess its images\n",
    "    print('Preprocessing', self._images_in_folder, file=sys.stderr)\n",
    "    # Detect landmarks in each image and write it to a CSV file\n",
    "    messages = []\n",
    "    temp_folder = tempfile.mkdtemp()\n",
    "    with open(f'{temp_folder}/temp.csv', 'w') as csv_out_file:\n",
    "      # Get list of images\n",
    "      image_names = sorted([n for n in os.listdir(self._images_in_folder) if not n.startswith('.')])\n",
    "      csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "      # Detect pose landmarks from each image\n",
    "      valid_image_count = 0\n",
    "      for image_name in tqdm.tqdm(image_names):\n",
    "        image_path = os.path.join(self._images_in_folder, image_name)\n",
    "        try:\n",
    "          image = tf.io.decode_jpeg(tf.io.read_file(image_path))\n",
    "          _, _, channel = image.shape\n",
    "        except:\n",
    "          messages.append('Skipped ' + image_path + '. Invalid image.')\n",
    "          continue\n",
    "        # Skip images that isn't RGB because Movenet requires RGB images\n",
    "        if channel != 3:\n",
    "          messages.append('Skipped ' + image_path + '. Image isn\\'t in RGB format.')\n",
    "          continue\n",
    "        person = detect(image)\n",
    "        # Save landmarks if all landmarks were detected\n",
    "        min_landmark_score = min([keypoint.score for keypoint in person.keypoints])\n",
    "        if not min_landmark_score >= detection_threshold:\n",
    "          messages.append('Skipped ' + image_path + '. No pose was confidentlly detected.')\n",
    "          continue\n",
    "        # Get landmarks and scale it to the same size as the input image\n",
    "        pose_landmarks = np.array([[keypoint.coordinate.x, keypoint.coordinate.y, keypoint.score]\n",
    "                                   for keypoint in person.keypoints], dtype=str)\n",
    "        # Write the landmark coordinates to its per-class CSV file\n",
    "        csv_out_writer.writerow([image_name] + pose_landmarks.flatten().tolist())\n",
    "        valid_image_count += 1\n",
    "      if not valid_image_count:\n",
    "        raise RuntimeError('No valid images found for the \"{}\" class.'.format(self._images_in_folder))\n",
    "    # Print the error message collected during preprocessing.\n",
    "    print('\\n'.join(messages))\n",
    "    # For the first class, assign its data to the total dataframe\n",
    "    total_df = pd.read_csv(f'{temp_folder}/temp.csv', header=None) # Combine all per-class CSVs into a single output file\n",
    "    list_name = [[bodypart.name + '_x', bodypart.name + '_y', bodypart.name + '_score'] for bodypart in BodyPart]\n",
    "    header_name = ['file_name']\n",
    "    for columns_name in list_name:\n",
    "      header_name += columns_name\n",
    "    header_map = {total_df.columns[i]: header_name[i] for i in range(len(header_name))}\n",
    "    total_df.rename(header_map, axis=1, inplace=True)\n",
    "    total_df.to_csv(self._csvs_out_path, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class MoveNetClassifier(object):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self, model_path=None):\n",
    "        self.model = keras.models.load_model(model_path)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def load_pose_landmarks(csv_path):\n",
    "  # Load the CSV file\n",
    "  dataframe = pd.read_csv(csv_path)\n",
    "  # Convert the input features and labels into the correct format for training.\n",
    "  return dataframe.pop('file_name'), dataframe.astype('float64')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing ./data\\predict\n",
      "100%|██████████| 24/24 [00:02<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1 [==============================] - 0s 165ms/step\n"
     ]
    }
   ],
   "source": [
    "images_folder = os.path.join(\"./data\", 'predict')\n",
    "csvs_path = tempfile.mkdtemp() + \"/predict.csv\"\n",
    "with open(f'./pose_labels.txt', 'r') as csv_out_file:\n",
    "  class_names = list(csv_out_file)\n",
    "movenetmark = MoveNetMark(images_in_folder=images_folder, csvs_out_path=csvs_path)\n",
    "movenetmark.process()\n",
    "# Load the data\n",
    "data_filename, data_value = load_pose_landmarks(csvs_path)\n",
    "\n",
    "classifier = MoveNetClassifier()\n",
    "classifier.build_model(\"./model/classifier\")\n",
    "# Classify pose in the TEST dataset using the trained model\n",
    "y_pred = classifier.predict(data_value)\n",
    "y_pred_label = [class_names[i].rstrip() for i in np.argmax(y_pred, axis=1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guy3_chair070.jpg is chair\n",
      "guy3_chair071.jpg is chair\n",
      "guy3_chair072.jpg is chair\n",
      "guy3_chair073.jpg is chair\n",
      "guy3_chair074.jpg is chair\n",
      "guy3_chair075.jpg is chair\n",
      "guy3_chair076.jpg is chair\n",
      "guy3_chair077.jpg is chair\n",
      "guy3_chair078.jpg is chair\n",
      "guy3_chair079.jpg is chair\n",
      "guy3_chair080.jpg is chair\n",
      "guy3_chair081.jpg is chair\n",
      "guy3_cobra025.jpg is cobra\n",
      "guy3_cobra026.jpg is cobra\n",
      "guy3_cobra027.jpg is cobra\n",
      "guy3_cobra028.jpg is cobra\n",
      "guy3_cobra029.jpg is cobra\n",
      "guy3_cobra030.jpg is cobra\n",
      "guy3_cobra031.jpg is cobra\n",
      "guy3_cobra032.jpg is cobra\n",
      "guy3_cobra033.jpg is cobra\n",
      "guy3_cobra034.jpg is cobra\n",
      "guy3_cobra035.jpg is cobra\n",
      "guy3_cobra036.jpg is cobra\n"
     ]
    }
   ],
   "source": [
    "for f, p in zip(data_filename, y_pred_label):\n",
    "  print(f\"{f} is {p}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
